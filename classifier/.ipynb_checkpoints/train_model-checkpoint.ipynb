{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c39e4d60-3b1d-e87d-b6aa-c0809438ff7d"
   },
   "source": [
    "In attempting to solve this problem, I apply feature transformation and dimensionality reduction techniques so as to increase the quality of the feature space. I compare multiple classification algorithms and choose the one that performs best on a separate test dataset. Also, I apply probability calibration methods based on isotonic regression to increase the quality of class probability estimates of my classifier. Lastly, I simulate making bets using my prediction model on the test set and observe the resulting return on investment. The optimal solution would be a classification algorithm with better performance than bookkeeper predictions and a betting strategy powered by said prediction algorithm that achieves positive returns on investment when betting on football matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "21de67ac-0da9-1da6-b220-4cb24d29bf85"
   },
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "## Fetching data\n",
    "#Connecting to database\n",
    "path = \"soccer/\"  #Insert path here\n",
    "database = path + 'database.sqlite'\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "#Defining the number of jobs to be run in parallel during grid search\n",
    "n_jobs = 1 #Insert number of parallel jobs here\n",
    "\n",
    "#Fetching required data tables\n",
    "player_data = pd.read_sql(\"SELECT * FROM Player;\", conn)\n",
    "player_stats_data = pd.read_sql(\"SELECT * FROM Player_Attributes;\", conn)\n",
    "team_data = pd.read_sql(\"SELECT * FROM Team;\", conn)\n",
    "match_data = pd.read_sql(\"SELECT * FROM Match;\", conn)\n",
    "\n",
    "#Reduce match data to fulfill run time requirements\n",
    "rows = [\"country_id\", \"league_id\", \"season\", \"stage\", \"date\", \"match_api_id\", \"home_team_api_id\", \n",
    "        \"away_team_api_id\", \"home_team_goal\", \"away_team_goal\", \"home_player_1\", \"home_player_2\",\n",
    "        \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\", \n",
    "        \"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\",\n",
    "        \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\",\n",
    "        \"away_player_7\", \"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]\n",
    "match_data.dropna(subset = rows, inplace = True)\n",
    "match_data = match_data.tail(1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading all functions\n",
    "def get_match_label(match):\n",
    "    '''\n",
    "    Derives a label for a given match.\n",
    "    '''\n",
    "    #Define variables\n",
    "    home_goals = match['home_team_goal']\n",
    "    away_goals = match['away_team_goal']\n",
    "    label = pd.DataFrame()\n",
    "    label.loc[0,'match_api_id'] = match['match_api_id'] \n",
    "    #Identify match label  \n",
    "    if home_goals > away_goals:\n",
    "        label.loc[0,'label'] = \"Win\"\n",
    "    if home_goals == away_goals:\n",
    "        label.loc[0,'label'] = \"Draw\"\n",
    "    if home_goals < away_goals:\n",
    "        label.loc[0,'label'] = \"Defeat\"\n",
    "    #Return label        \n",
    "    return label.loc[0]\n",
    "    \n",
    "def get_fifa_stats(match, player_stats):\n",
    "    ''' Aggregates fifa stats for a given match. '''    \n",
    "    #Define variables\n",
    "    match_id =  match.match_api_id\n",
    "    date = match['date']\n",
    "    players = ['home_player_1', 'home_player_2', 'home_player_3', \"home_player_4\", \"home_player_5\",\n",
    "               \"home_player_6\", \"home_player_7\", \"home_player_8\", \"home_player_9\", \"home_player_10\",\n",
    "               \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\",\n",
    "               \"away_player_5\", \"away_player_6\", \"away_player_7\", \"away_player_8\", \"away_player_9\",\n",
    "               \"away_player_10\", \"away_player_11\"]\n",
    "    player_stats_new = pd.DataFrame()\n",
    "    names = []\n",
    "    #Loop through all players\n",
    "    for player in players:       \n",
    "        #Get player ID\n",
    "        player_id = match[player]\n",
    "        #Get player stats \n",
    "        stats = player_stats[player_stats.player_api_id == player_id]   \n",
    "        #Identify current stats       \n",
    "        current_stats = stats[stats.date < date].sort_values(by = 'date', ascending = False)[:1]\n",
    "        if np.isnan(player_id) == True:\n",
    "            overall_rating = pd.Series(0)\n",
    "        else:\n",
    "            current_stats.reset_index(inplace = True, drop = True)\n",
    "            overall_rating = pd.Series(current_stats.loc[0, \"overall_rating\"])\n",
    "        #Rename stat\n",
    "        name = \"{}_overall_rating\".format(player)\n",
    "        names.append(name)   \n",
    "        #Aggregate stats\n",
    "        player_stats_new = pd.concat([player_stats_new, overall_rating], axis = 1)\n",
    "    player_stats_new.columns = names        \n",
    "    player_stats_new['match_api_id'] = match_id\n",
    "    player_stats_new.reset_index(inplace = True, drop = True)\n",
    "    #Return player stats    \n",
    "    return player_stats_new.iloc[0]     \n",
    "      \n",
    "def get_fifa_data(matches, player_stats, path = None, data_exists = False):\n",
    "    ''' Gets fifa data for all matches. '''  \n",
    "    #Check if fifa data already exists\n",
    "    if data_exists == True:\n",
    "        fifa_data = pd.read_pickle(path)\n",
    "    else:\n",
    "        print(\"Collecting fifa data for each match...\")       \n",
    "        start = time()\n",
    "        #Apply get_fifa_stats for each match\n",
    "        fifa_data = matches.apply(lambda x :get_fifa_stats(x, player_stats), axis = 1)\n",
    "        end = time()    \n",
    "        print(\"Fifa data collected in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    return None\n",
    "    \n",
    "    return fifa_data\n",
    "\n",
    "def get_overall_fifa_rankings(fifa, get_overall = False):\n",
    "    ''' Get overall fifa rankings from fifa data. '''\n",
    "    temp_data = fifa\n",
    "    #Check if only overall player stats are desired\n",
    "    if get_overall == True:\n",
    "        #Get overall stats\n",
    "        data = temp_data.loc[:,(fifa.columns.str.contains('overall_rating'))]\n",
    "        data.loc[:,'match_api_id'] = temp_data.loc[:,'match_api_id']\n",
    "    else:\n",
    "        #Get all stats except for stat date\n",
    "        cols = fifa.loc[:,(fifa.columns.str.contains('date_stat'))]\n",
    "        temp_data = fifa.drop(cols.columns, axis = 1)        \n",
    "        data = temp_data\n",
    "    #Return data\n",
    "    return data\n",
    "\n",
    "def get_last_matches(matches, date, team, x = 10):\n",
    "    ''' Get the last x matches of a given team. '''\n",
    "    #Filter team matches from matches\n",
    "    team_matches = matches[(matches['home_team_api_id'] == team) | (matches['away_team_api_id'] == team)]\n",
    "    #Filter x last matches from team matches\n",
    "    last_matches = team_matches[team_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    #Return last matches\n",
    "    return last_matches\n",
    "    \n",
    "def get_last_matches_against_eachother(matches, date, home_team, away_team, x = 10):\n",
    "    ''' Get the last x matches of two given teams. '''\n",
    "    #Find matches of both teams\n",
    "    home_matches = matches[(matches['home_team_api_id'] == home_team) & (matches['away_team_api_id'] == away_team)]    \n",
    "    away_matches = matches[(matches['home_team_api_id'] == away_team) & (matches['away_team_api_id'] == home_team)]  \n",
    "    total_matches = pd.concat([home_matches, away_matches])\n",
    "    #Get last x matches\n",
    "    try:    \n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    except:\n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:total_matches.shape[0],:]\n",
    "        \n",
    "        #Check for error in data\n",
    "        if(last_matches.shape[0] > x):\n",
    "            print(\"Error in obtaining matches\")\n",
    "    #Return data\n",
    "    return last_matches\n",
    "    \n",
    "def get_goals(matches, team):\n",
    "    ''' Get the goals of a specfic team from a set of matches. '''\n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.home_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.away_team_api_id == team].sum())\n",
    "    total_goals = home_goals + away_goals\n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_goals_conceided(matches, team):\n",
    "    ''' Get the goals conceided of a specfic team from a set of matches. '''\n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.away_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.home_team_api_id == team].sum())\n",
    "    total_goals = home_goals + away_goals\n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "def get_wins(matches, team):\n",
    "    ''' Get the number of wins of a specfic team from a set of matches. '''\n",
    "    #Find home and away wins\n",
    "    home_wins = int(matches.home_team_goal[(matches.home_team_api_id == team) & (matches.home_team_goal > matches.away_team_goal)].count())\n",
    "    away_wins = int(matches.away_team_goal[(matches.away_team_api_id == team) & (matches.away_team_goal > matches.home_team_goal)].count())\n",
    "    total_wins = home_wins + away_wins\n",
    "    return total_wins      \n",
    "    \n",
    "def get_match_features(match, matches, x = 10):\n",
    "    ''' Create match specific features for a given match. '''\n",
    "    date = match.date\n",
    "    home_team = match.home_team_api_id\n",
    "    away_team = match.away_team_api_id\n",
    "    matches_home_team = get_last_matches(matches, date, home_team, x = 10)\n",
    "    matches_away_team = get_last_matches(matches, date, away_team, x = 10)\n",
    "    \n",
    "    #Get last x matches of both teams against each other\n",
    "    last_matches_against = get_last_matches_against_eachother(matches, date, home_team, away_team, x = 3)\n",
    "    #Create goal variables\n",
    "    home_goals = get_goals(matches_home_team, home_team)\n",
    "    away_goals = get_goals(matches_away_team, away_team)\n",
    "    home_goals_conceided = get_goals_conceided(matches_home_team, home_team)\n",
    "    away_goals_conceided = get_goals_conceided(matches_away_team, away_team)\n",
    "    #Define result data frame\n",
    "    result = pd.DataFrame()\n",
    "    #Define ID features\n",
    "    result.loc[0, 'match_api_id'] = match.match_api_id\n",
    "    result.loc[0, 'league_id'] = match.league_id\n",
    "    #Create match features\n",
    "    result.loc[0, 'home_team_goals_difference'] = home_goals - home_goals_conceided\n",
    "    result.loc[0, 'away_team_goals_difference'] = away_goals - away_goals_conceided\n",
    "    result.loc[0, 'games_won_home_team'] = get_wins(matches_home_team, home_team) \n",
    "    result.loc[0, 'games_won_away_team'] = get_wins(matches_away_team, away_team)\n",
    "    result.loc[0, 'games_against_won'] = get_wins(last_matches_against, home_team)\n",
    "    result.loc[0, 'games_against_lost'] = get_wins(last_matches_against, away_team)\n",
    "    return result.loc[0]\n",
    "    \n",
    "def create_feables(matches, fifa, bookkeepers, get_overall = False, horizontal = True, x = 10, verbose = True):\n",
    "    ''' Create and aggregate features and labels for all matches. '''\n",
    "    #Get fifa stats features\n",
    "#     fifa_stats = get_overall_fifa_rankings(fifa, get_overall)\n",
    "    if verbose == True:\n",
    "        print(\"Generating match features...\")\n",
    "    start = time()\n",
    "    #Get match features for all matches\n",
    "    match_stats = matches.apply(lambda x: get_match_features(x, matches, x = 10), axis = 1)\n",
    "    #Create dummies for league ID feature\n",
    "    print('match stats done')\n",
    "    dummies = pd.get_dummies(match_stats['league_id']).rename(columns = lambda x: 'League_' + str(x))\n",
    "    match_stats = pd.concat([match_stats, dummies], axis = 1)\n",
    "    match_stats.drop(['league_id'], inplace = True, axis = 1)\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match features generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    if verbose == True:    \n",
    "        print(\"Generating match labels...\")\n",
    "    start = time()\n",
    "    #Create match labels\n",
    "    labels = matches.apply(get_match_label, axis = 1)\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match labels generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    if verbose == True:    \n",
    "        print(\"Generating bookkeeper data...\")\n",
    "    start = time()\n",
    "    #Get bookkeeper quotas for all matches\n",
    "    bk_data = get_bookkeeper_data(matches, bookkeepers, horizontal = True)\n",
    "    bk_data.loc[:,'match_api_id'] = matches.loc[:,'match_api_id']\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Bookkeeper data generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    #Merges features and labels into one frame\n",
    "#     features = pd.merge(match_stats, fifa_stats, on = 'match_api_id', how = 'left')\n",
    "#     features = pd.merge(features, bk_data, on = 'match_api_id', how = 'left')\n",
    "    features = pd.merge(match_stats, bk_data, on = 'match_api_id', how = 'left')\n",
    "    feables = pd.merge(features, labels, on = 'match_api_id', how = 'left')\n",
    "    #Drop NA values\n",
    "    feables.dropna(inplace = True)\n",
    "    #Return preprocessed data\n",
    "    return feables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER/BETS\n",
    "\n",
    "\n",
    "def train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs, use_grid_search = True, \n",
    "                     best_components = None, best_params = None):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    #Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    #Check if grid search should be applied\n",
    "    if use_grid_search == True: \n",
    "        #Define pipeline of dm reduction and classifier\n",
    "        estimators = [('dm_reduce', dm_reduction), ('clf', clf)]\n",
    "        pipeline = Pipeline(estimators)\n",
    "        #Grid search over pipeline and return best classifier\n",
    "        grid_obj = model_selection.GridSearchCV(pipeline, param_grid = params, scoring = scorer, cv = cv_sets, n_jobs = jobs)\n",
    "        grid_obj.fit(X_train, y_train)\n",
    "        best_pipe = grid_obj.best_estimator_\n",
    "    else:\n",
    "        #Use best components that are known without grid search        \n",
    "        estimators = [('dm_reduce', dm_reduction(n_components = best_components)), ('clf', clf(best_params))]\n",
    "        pipeline = Pipeline(estimators)        \n",
    "        best_pipe = pipeline.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    #Print the results    \n",
    "    #Return best pipe\n",
    "    return best_pipe\n",
    "    \n",
    "def predict_labels(clf, best_pipe, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on scorer. '''\n",
    "    \n",
    "    #Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(best_pipe.named_steps['dm_reduce'].transform(features))\n",
    "    end = time()\n",
    "    \n",
    "    #Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds\".format(end - start))\n",
    "    return accuracy_score(target.values, y_pred)\n",
    "    \n",
    "def train_calibrate_predict(clf, dm_reduction, X_train, y_train, X_calibrate, y_calibrate, X_test, y_test, cv_sets, params, scorer, jobs, \n",
    "                            use_grid_search = True, **kwargs):\n",
    "    ''' Train and predict using a classifer based on scorer. '''\n",
    "    \n",
    "    #Indicate the classifier and the training set size\n",
    "    print(\"Training a {} with {}...\".format(clf.__class__.__name__, dm_reduction.__class__.__name__))\n",
    "    \n",
    "    #Train the classifier\n",
    "    best_pipe = train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs)\n",
    "    \n",
    "    #Calibrate classifier\n",
    "    print(\"Calibrating probabilities of classifier...\")\n",
    "    start = time()    \n",
    "    clf = CalibratedClassifierCV(best_pipe.named_steps['clf'], cv= 'prefit', method='isotonic')\n",
    "    clf.fit(best_pipe.named_steps['dm_reduce'].transform(X_calibrate), y_calibrate)\n",
    "    end = time()\n",
    "    print(\"Calibrated {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Score of {} for training set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_train, y_train)))\n",
    "    print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_test, y_test)))\n",
    "    \n",
    "    #Return classifier, dm reduction, and label predictions for train and test set\n",
    "    return clf, best_pipe.named_steps['dm_reduce'], predict_labels(clf, best_pipe, X_train, y_train), predict_labels(clf, best_pipe, X_test, y_test)\n",
    "        \n",
    "def convert_odds_to_prob(match_odds):\n",
    "    ''' Converts bookkeeper odds to probabilities. '''\n",
    "    \n",
    "    #Define variables\n",
    "    match_id = match_odds.loc[:,'match_api_id']\n",
    "    bookkeeper = match_odds.loc[:,'bookkeeper']    \n",
    "    win_odd = match_odds.loc[:,'Win']\n",
    "    draw_odd = match_odds.loc[:,'Draw']\n",
    "    loss_odd = match_odds.loc[:,'Defeat']\n",
    "    \n",
    "    #Converts odds to prob\n",
    "    win_prob = 1 / win_odd\n",
    "    draw_prob = 1 / draw_odd\n",
    "    loss_prob = 1 / loss_odd\n",
    "    \n",
    "    total_prob = win_prob + draw_prob + loss_prob\n",
    "    \n",
    "    probs = pd.DataFrame()\n",
    "    \n",
    "    #Define output format and scale probs by sum over all probs\n",
    "    probs.loc[:,'match_api_id'] = match_id\n",
    "    probs.loc[:,'bookkeeper'] = bookkeeper\n",
    "    probs.loc[:,'Win'] = win_prob / total_prob\n",
    "    probs.loc[:,'Draw'] = draw_prob / total_prob\n",
    "    probs.loc[:,'Defeat'] = loss_prob / total_prob\n",
    "    \n",
    "    #Return probs and meta data\n",
    "    return probs\n",
    "    \n",
    "def get_bookkeeper_data(matches, bookkeepers, horizontal = True):\n",
    "    ''' Aggregates bookkeeper data for all matches and bookkeepers. '''\n",
    "    \n",
    "    bk_data = pd.DataFrame()\n",
    "    \n",
    "    #Loop through bookkeepers\n",
    "    for bookkeeper in bookkeepers:\n",
    "\n",
    "        #Find columns containing data of bookkeeper\n",
    "        temp_data = matches.loc[:,(matches.columns.str.contains(bookkeeper))]\n",
    "        temp_data.loc[:, 'bookkeeper'] = str(bookkeeper)\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "        \n",
    "        #Rename odds columns and convert to numeric\n",
    "        cols = temp_data.columns.values\n",
    "        cols[:3] = ['Win','Draw','Defeat']\n",
    "        temp_data.columns = cols\n",
    "        temp_data.loc[:,'Win'] = pd.to_numeric(temp_data['Win'])\n",
    "        temp_data.loc[:,'Draw'] = pd.to_numeric(temp_data['Draw'])\n",
    "        temp_data.loc[:,'Defeat'] = pd.to_numeric(temp_data['Defeat'])\n",
    "        \n",
    "        #Check if data should be aggregated horizontally\n",
    "        if(horizontal == True):\n",
    "            \n",
    "            #Convert data to probs\n",
    "            temp_data = convert_odds_to_prob(temp_data)\n",
    "            temp_data.drop('match_api_id', axis = 1, inplace = True)\n",
    "            temp_data.drop('bookkeeper', axis = 1, inplace = True)\n",
    "            \n",
    "            #Rename columns with bookkeeper names\n",
    "            win_name = bookkeeper + \"_\" + \"Win\"\n",
    "            draw_name = bookkeeper + \"_\" + \"Draw\"\n",
    "            defeat_name = bookkeeper + \"_\" + \"Defeat\"\n",
    "            temp_data.columns.values[:3] = [win_name, draw_name, defeat_name]\n",
    "\n",
    "            #Aggregate data\n",
    "            bk_data = pd.concat([bk_data, temp_data], axis = 1)\n",
    "        else:\n",
    "            #Aggregate vertically\n",
    "            bk_data = bk_data.append(temp_data, ignore_index = True)\n",
    "    \n",
    "    #If horizontal add match api id to data\n",
    "    if(horizontal == True):\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "    \n",
    "    #Return bookkeeper data\n",
    "    return bk_data\n",
    "    \n",
    "def get_bookkeeper_probs(matches, bookkeepers, horizontal = False):\n",
    "    ''' Get bookkeeper data and convert to probabilities for vertical aggregation. '''\n",
    "    \n",
    "    #Get bookkeeper data\n",
    "    data = get_bookkeeper_data(matches, bookkeepers, horizontal = False)\n",
    "    \n",
    "    #Convert odds to probabilities\n",
    "    probs = convert_odds_to_prob(data)\n",
    "    \n",
    "    #Return data\n",
    "    return probs\n",
    "\n",
    "def plot_confusion_matrix(y_test, X_test, clf, dim_reduce, path, cmap=plt.cm.Blues, normalize = False):    \n",
    "    ''' Plot confusion matrix for given classifier and data. '''\n",
    "    \n",
    "    #Define label names and get confusion matrix values\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, clf.predict(dim_reduce.transform(X_test)), labels)\n",
    "    \n",
    "    #Check if matrix should be normalized\n",
    "    if normalize == True:\n",
    "        \n",
    "        #Normalize\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Configure figure\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title= \"Confusion matrix of a {} with {}\".format(best_clf.base_estimator.__class__.__name__, best_dm_reduce.__class__.__name__)   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report\n",
    "    y_pred = clf.predict(dim_reduce.transform(X_test))\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "\n",
    "def compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False):\n",
    "    ''' Map bookkeeper and model probabilities. '''\n",
    "    \n",
    "    #Create features and labels for given matches\n",
    "    feables = create_feables(matches, fifa_data, bk, get_overall = True, verbose = False)\n",
    "    \n",
    "    #Ensure consistency\n",
    "    match_ids = list(feables['match_api_id'])\n",
    "    matches = matches[matches['match_api_id'].isin(match_ids)]\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Obtaining bookkeeper probabilities...\")\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    inputs = feables.drop('match_api_id', axis = 1)\n",
    "    labels = inputs.loc[:,'label']\n",
    "    features = inputs.drop('label', axis = 1)\n",
    "    \n",
    "    #Get model probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Predicting probabilities based on model...\")\n",
    "    model_probs = pd.DataFrame()\n",
    "    label_table = pd.Series()\n",
    "    temp_probs = pd.DataFrame(clf.predict_proba(dim_reduce.transform(features)), columns = ['win_prob', 'draw_prob', 'defeat_prob'])\n",
    "    for bookkeeper in bookkeepers:\n",
    "        model_probs = model_probs.append(temp_probs, ignore_index = True)\n",
    "        label_table = label_table.append(labels)\n",
    "    model_probs.reset_index(inplace = True, drop = True)\n",
    "    label_table.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs['win_prob'] = model_probs['win_prob']\n",
    "    bookkeeper_probs['draw_prob'] = model_probs['draw_prob']\n",
    "    bookkeeper_probs['defeat_prob'] = model_probs['defeat_prob']\n",
    "    bookkeeper_probs['label'] = label_table \n",
    "    \n",
    "    #Aggregate win probabilities for each match\n",
    "    wins = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Win', 'win_prob', 'label']]\n",
    "    wins.loc[:, 'bet'] = 'Win'\n",
    "    wins = wins.rename(columns = {'Win':'bookkeeper_prob',\n",
    "                                  'win_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate draw probabilities for each match\n",
    "    draws = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Draw', 'draw_prob', 'label']]\n",
    "    draws.loc[:, 'bet'] = 'Draw'\n",
    "    draws = draws.rename(columns = {'Draw':'bookkeeper_prob',\n",
    "                                  'draw_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate defeat probabilities for each match\n",
    "    defeats = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Defeat', 'defeat_prob', 'label']]\n",
    "    defeats.loc[:, 'bet'] = 'Defeat'\n",
    "    defeats = defeats.rename(columns = {'Defeat':'bookkeeper_prob',\n",
    "                                  'defeat_prob': 'model_prob'})\n",
    "    \n",
    "    total = pd.concat([wins, draws, defeats])\n",
    "    \n",
    "    #Return total\n",
    "    return total\n",
    "    \n",
    "def find_good_bets(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, percentile, prob_cap, verbose = False):\n",
    "    ''' Find good bets for a given classifier and matches. '''\n",
    "    \n",
    "    #Compare model and classifier probabilities\n",
    "    probs = compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False)\n",
    "    probs.loc[:, 'prob_difference'] = probs.loc[:,\"model_prob\"] - probs.loc[:,\"bookkeeper_prob\"]\n",
    "    \n",
    "    #Sort by createst difference to identify most underestimated bets    \n",
    "    values = probs['prob_difference']\n",
    "    values = values.sort_values(ascending = False)\n",
    "    values.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Selecting attractive bets...\")\n",
    "        \n",
    "    #Identify choices that fulfill requirements such as positive difference, minimum probability and match outcome\n",
    "    relevant_choices = probs[(probs.prob_difference > 0) & (probs.model_prob > prob_cap) & (probs.bet != \"Draw\")]\n",
    "    \n",
    "    #Select given percentile of relevant choices    \n",
    "    top_percent = 1 - percentile\n",
    "    choices = relevant_choices[relevant_choices.prob_difference >= relevant_choices.prob_difference.quantile(top_percent)]\n",
    "    choices.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Return choices\n",
    "    return choices\n",
    "\n",
    "def get_reward(choice, matches):\n",
    "    ''' Get the reward of a given bet. '''\n",
    "    \n",
    "    #Identify bet\n",
    "    match = matches[matches.match_api_id == choice.match_api_id]\n",
    "    bet_data = match.loc[:,(match.columns.str.contains(choice.bookkeeper))]\n",
    "    cols = bet_data.columns.values\n",
    "    cols[:3] = ['win','draw','defeat']\n",
    "    bet_data.columns = cols\n",
    "    \n",
    "    #Identfiy bet type and get quota\n",
    "    if choice.bet == 'Win':\n",
    "        bet_quota = bet_data.win.values\n",
    "    elif choice.bet == 'Draw':\n",
    "        bet_quota = bet_data.draw.values\n",
    "    elif choice.bet == 'Defeat':\n",
    "        bet_quota = bet_data.defeat.values\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    #Check label and compute reward\n",
    "    if choice.bet == choice.label:\n",
    "        reward = bet_quota\n",
    "    else:\n",
    "        reward = 0\n",
    "    \n",
    "    #Return reward\n",
    "    return reward\n",
    "      \n",
    "def execute_bets(bet_choices, matches, verbose = False):\n",
    "    ''' Get rewards for all bets. '''    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Obtaining reward for chosen bets...\")\n",
    "    total_reward = 0\n",
    "    total_invested = 0\n",
    "    \n",
    "    #Loop through bets\n",
    "    loops = np.arange(0, bet_choices.shape[0])     \n",
    "    for i in loops:\n",
    "        \n",
    "        #Get rewards and accumulate profit\n",
    "        reward = get_reward(bet_choices.iloc[i,:], matches)\n",
    "        total_reward = total_reward + reward\n",
    "        total_invested += 1\n",
    "    \n",
    "    #Compute investment return\n",
    "    investment_return = float(total_reward / total_invested) - 1\n",
    "    \n",
    "    #Return investment return\n",
    "    return investment_return\n",
    "    \n",
    "def explore_data(features, inputs, path):\n",
    "    ''' Explore data by plotting KDE graphs. '''\n",
    "    #Define figure subplots\n",
    "    fig = plt.figure(1)\n",
    "    fig.subplots_adjust(bottom= -1, left=0.025, top = 2, right=0.975)\n",
    "    #Loop through features    \n",
    "    i = 1\n",
    "    for col in features.columns:\n",
    "        #Set subplot and plot format        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_context(\"paper\", font_scale = 0.5, rc={\"lines.linewidth\": 1})\n",
    "        plt.subplot(7,7,0 + i)\n",
    "        j = i - 1\n",
    "        \n",
    "        #Plot KDE for all labels\n",
    "        sns.distplot(inputs[inputs['label'] == 'Win'].iloc[:,j], hist = False, label = 'Win')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Draw'].iloc[:,j], hist = False, label = 'Draw')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Defeat'].iloc[:,j], hist = False, label = 'Defeat')\n",
    "        plt.legend();\n",
    "        i = i + 1\n",
    "    #Define plot format    \n",
    "    DefaultSize = fig.get_size_inches()\n",
    "    fig.set_size_inches((DefaultSize[0]*1.2, DefaultSize[1]*1.2))\n",
    "    plt.show()\n",
    "    #Compute and print label weights\n",
    "    labels = inputs.loc[:,'label']\n",
    "    class_weights = labels.value_counts() / len(labels)\n",
    "    print(class_weights)\n",
    "    #Store description of all features\n",
    "    feature_details = features.describe().transpose()\n",
    "    #Return feature details\n",
    "    return feature_details\n",
    "    \n",
    "def find_best_classifier(classifiers, dm_reductions, scorer, X_t, y_t, X_c, y_c, X_v, y_v, cv_sets, params, jobs):\n",
    "    ''' Tune all classifier and dimensionality reduction combiantions to find best classifier. '''\n",
    "    \n",
    "    #Initialize result storage\n",
    "    clfs_return = []\n",
    "    dm_reduce_return = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    #Loop through dimensionality reductions\n",
    "    for dm in dm_reductions:\n",
    "        \n",
    "        #Loop through classifiers\n",
    "        for clf in clfs:\n",
    "            \n",
    "            #Grid search, calibrate, and test the classifier\n",
    "            clf, dm_reduce, train_score, test_score = train_calibrate_predict(clf = clf, dm_reduction = dm, X_train = X_t, y_train = y_t,\n",
    "                                                      X_calibrate = X_c, y_calibrate = y_c,\n",
    "                                                      X_test = X_v, y_test = y_v, cv_sets = cv_sets,\n",
    "                                                      params = params[clf], scorer = scorer, jobs = jobs, use_grid_search = True)\n",
    "            \n",
    "            #Append the result to storage            \n",
    "            clfs_return.append(clf)\n",
    "            dm_reduce_return.append(dm_reduce)\n",
    "            train_scores.append(train_score)\n",
    "            test_scores.append(test_score)\n",
    "    \n",
    "    #Return storage\n",
    "    return clfs_return, dm_reduce_return, train_scores, test_scores\n",
    "\n",
    "def plot_training_results(clfs, dm_reductions, train_scores, test_scores, path):\n",
    "    ''' Plot results of classifier training. '''\n",
    "    \n",
    "    #Set graph format\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale = 1, rc={\"lines.linewidth\": 1})\n",
    "    ax = plt.subplot(111)\n",
    "    w = 0.5\n",
    "    x = np.arange(len(train_scores))\n",
    "    ax.set_yticks(x + w)\n",
    "    ax.legend((train_scores[0], test_scores[0]), (\"Train Scores\", \"Test Scores\"))\n",
    "    names = []\n",
    "    \n",
    "    #Loop throuugh classifiers\n",
    "    for i in range(0, len(clfs)): \n",
    "        \n",
    "        #Define temporary variables        \n",
    "        clf = clfs[i]\n",
    "        clf_name = clf.base_estimator.__class__.__name__\n",
    "        dm = dm_reductions[i]\n",
    "        dm_name = dm.__class__.__name__\n",
    "        \n",
    "        #Create and store name\n",
    "        name = \"{} with {}\".format(clf_name, dm_name)\n",
    "        names.append(name)\n",
    "        \n",
    "    #Plot all names in horizontal bar plot\n",
    "    ax.set_yticklabels((names))\n",
    "    plt.xlim(0.5, 0.55)\n",
    "    plt.barh(x, test_scores, color = 'b', alpha = 0.6)\n",
    "    plt.title(\"Test Data Accuracy Scores\")\n",
    "    fig = plt.figure(1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def optimize_betting(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, match_data, fifa_data,\n",
    "                     n_samples, sample_size, parameter_1_grid, parameter_2_grid, verbose = False):\n",
    "    ''' Tune parameters of bet selection algorithm. '''\n",
    "    \n",
    "    #Generate data samples\n",
    "    samples = []\n",
    "    for i in range(0, n_samples):\n",
    "        sample = match_data.sample(n = sample_size, random_state = 42)\n",
    "        samples.append(sample)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [\"parameter_1\", \"parameter_2\", \"results\"])\n",
    "    row = 0\n",
    "    \n",
    "    #Iterate over all 1 parameter\n",
    "    for i in parameter_1_grid:\n",
    "        \n",
    "        #Iterate over all 2 parameter\n",
    "        for j in parameter_2_grid:\n",
    "            \n",
    "            #Compute average score over all samples\n",
    "            profits = []\n",
    "            for sample in samples:\n",
    "                choices = find_good_bets(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, sample, fifa_data, i, j)\n",
    "                profit = execute_bets(choices, match_data)\n",
    "                profits.append(profit)\n",
    "            result = np.mean(np.array(profits))\n",
    "            results.loc[row,\"results\"] = result\n",
    "            results.loc[row,\"parameter_1\"] = i\n",
    "            results.loc[row,\"parameter_2\"] = j\n",
    "            row = row + 1\n",
    "            if verbose == True: print(\"Simulated parameter combination: {}\".format(row))\n",
    "               \n",
    "    #Return best setting and result\n",
    "    best_result = results.iloc[results['results'].idxmax()] \n",
    "    return best_result\n",
    "    \n",
    "    \n",
    "def plot_bookkeeper_cf_matrix(matches, bookkeepers, path, verbose = False, normalize = True):\n",
    "    ''' Plot confusion matrix of bookkeeper predictions. '''\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining labels...\")\n",
    "    \n",
    "    #Get match labels\n",
    "    y_test_temp = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper probabilities...\")\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs.dropna(inplace = True)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper labels...\")\n",
    "    \n",
    "    #Get bookkeeper labels\n",
    "    y_pred_temp = pd.DataFrame()\n",
    "    y_pred_temp.loc[:,'bk_label'] = bookkeeper_probs[['Win', 'Draw', 'Defeat']].idxmax(axis = 1)\n",
    "    y_pred_temp.loc[:,'match_api_id'] = bookkeeper_probs.loc[:, 'match_api_id']\n",
    "    \n",
    "    if verbose == True: print(\"Plotting confusion matrix...\")\n",
    "    \n",
    "    #Format data\n",
    "    results = pd.merge(y_pred_temp, y_test_temp, on = 'match_api_id', how = 'left')\n",
    "    y_test = results.loc[:, 'label']\n",
    "    y_pred = results.loc[:, 'bk_label']\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels) \n",
    "    \n",
    "    #Check for normalization\n",
    "    if normalize == True:\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Plot confusion matrix\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title = \"Confusion matrix of Bookkeeper predictions!\"   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report and accuracy score of bookkeepers\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "    print(\"Bookkeeper score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fifa data for each match...\n",
      "Fifa data collected in 1.7 minutes\n",
      "finished fifa data\n",
      "Generating match features...\n",
      "match stats done\n",
      "Match features generated in 0.6 minutes\n",
      "Generating match labels...\n",
      "Match labels generated in 0.1 minutes\n",
      "Generating bookkeeper data...\n",
      "Bookkeeper data generated in 0.0 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>home_team_goals_difference</th>\n",
       "      <th>away_team_goals_difference</th>\n",
       "      <th>games_won_home_team</th>\n",
       "      <th>games_won_away_team</th>\n",
       "      <th>games_against_won</th>\n",
       "      <th>games_against_lost</th>\n",
       "      <th>League_21518.0</th>\n",
       "      <th>League_24558.0</th>\n",
       "      <th>B365_Win</th>\n",
       "      <th>B365_Draw</th>\n",
       "      <th>B365_Defeat</th>\n",
       "      <th>BW_Win</th>\n",
       "      <th>BW_Draw</th>\n",
       "      <th>BW_Defeat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030192.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395683</td>\n",
       "      <td>0.287770</td>\n",
       "      <td>0.316547</td>\n",
       "      <td>0.389704</td>\n",
       "      <td>0.287782</td>\n",
       "      <td>0.322514</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030193.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624582</td>\n",
       "      <td>0.238903</td>\n",
       "      <td>0.136516</td>\n",
       "      <td>0.612713</td>\n",
       "      <td>0.253365</td>\n",
       "      <td>0.133922</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030194.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.260465</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.380496</td>\n",
       "      <td>0.279776</td>\n",
       "      <td>0.339728</td>\n",
       "      <td>Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030196.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360875</td>\n",
       "      <td>0.287606</td>\n",
       "      <td>0.351519</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030197.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>0.125093</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.224066</td>\n",
       "      <td>0.141079</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2030167.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604340</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>0.145971</td>\n",
       "      <td>0.611981</td>\n",
       "      <td>0.240202</td>\n",
       "      <td>0.147817</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2030168.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424796</td>\n",
       "      <td>0.294089</td>\n",
       "      <td>0.281115</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.301282</td>\n",
       "      <td>0.301282</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2030169.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624582</td>\n",
       "      <td>0.238903</td>\n",
       "      <td>0.136516</td>\n",
       "      <td>0.615021</td>\n",
       "      <td>0.238321</td>\n",
       "      <td>0.146659</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2030170.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.398977</td>\n",
       "      <td>0.288491</td>\n",
       "      <td>0.312532</td>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2030171.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428346</td>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.294488</td>\n",
       "      <td>0.426261</td>\n",
       "      <td>0.274025</td>\n",
       "      <td>0.299715</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     match_api_id  home_team_goals_difference  away_team_goals_difference  \\\n",
       "0       2030192.0                        -5.0                        -8.0   \n",
       "1       2030193.0                         4.0                        -2.0   \n",
       "2       2030194.0                        18.0                         7.0   \n",
       "3       2030196.0                         1.0                         1.0   \n",
       "4       2030197.0                         1.0                         1.0   \n",
       "..            ...                         ...                         ...   \n",
       "317     2030167.0                         7.0                         2.0   \n",
       "318     2030168.0                        -4.0                         5.0   \n",
       "319     2030169.0                        -1.0                         0.0   \n",
       "320     2030170.0                        -7.0                        -4.0   \n",
       "321     2030171.0                       -11.0                        -6.0   \n",
       "\n",
       "     games_won_home_team  games_won_away_team  games_against_won  \\\n",
       "0                    2.0                  1.0                0.0   \n",
       "1                    4.0                  1.0                0.0   \n",
       "2                    6.0                  6.0                0.0   \n",
       "3                    2.0                  3.0                0.0   \n",
       "4                    3.0                  1.0                0.0   \n",
       "..                   ...                  ...                ...   \n",
       "317                  4.0                  3.0                0.0   \n",
       "318                  1.0                  3.0                0.0   \n",
       "319                  2.0                  2.0                0.0   \n",
       "320                  0.0                  3.0                0.0   \n",
       "321                  0.0                  3.0                0.0   \n",
       "\n",
       "     games_against_lost  League_21518.0  League_24558.0  B365_Win  B365_Draw  \\\n",
       "0                   0.0               1               0  0.395683   0.287770   \n",
       "1                   0.0               1               0  0.624582   0.238903   \n",
       "2                   0.0               1               0  0.390698   0.260465   \n",
       "3                   0.0               1               0  0.360875   0.287606   \n",
       "4                   0.0               1               0  0.651526   0.223380   \n",
       "..                  ...             ...             ...       ...        ...   \n",
       "317                 0.0               1               0  0.604340   0.249688   \n",
       "318                 0.0               1               0  0.424796   0.294089   \n",
       "319                 0.0               1               0  0.624582   0.238903   \n",
       "320                 0.0               1               0  0.414013   0.292994   \n",
       "321                 0.0               1               0  0.428346   0.277165   \n",
       "\n",
       "     B365_Defeat    BW_Win   BW_Draw  BW_Defeat   label  \n",
       "0       0.316547  0.389704  0.287782   0.322514    Draw  \n",
       "1       0.136516  0.612713  0.253365   0.133922    Draw  \n",
       "2       0.348837  0.380496  0.279776   0.339728  Defeat  \n",
       "3       0.351519  0.354839  0.290323   0.354839     Win  \n",
       "4       0.125093  0.634855  0.224066   0.141079    Draw  \n",
       "..           ...       ...       ...        ...     ...  \n",
       "317     0.145971  0.611981  0.240202   0.147817     Win  \n",
       "318     0.281115  0.397436  0.301282   0.301282     Win  \n",
       "319     0.136516  0.615021  0.238321   0.146659     Win  \n",
       "320     0.292994  0.398977  0.288491   0.312532    Draw  \n",
       "321     0.294488  0.426261  0.274025   0.299715     Win  \n",
       "\n",
       "[322 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generating features, exploring the data, and preparing data for model training\n",
    "#Generating or retrieving already existant FIFA data\n",
    "fifa_data = get_fifa_data(match_data, player_stats_data, data_exists = False)\n",
    "# fifa_data = None\n",
    "print('finished fifa data')\n",
    "#Creating features and labels based on data provided\n",
    "bk_cols = ['B365', 'BW', 'IW', 'LB', 'PS', 'WH', 'SJ', 'VC', 'GB', 'BS']\n",
    "bk_cols_selected = ['B365', 'BW']      \n",
    "# feables = create_feables(match_data.iloc[:-1500], fifa_data, bk_cols_selected, get_overall = True verbose=True)\n",
    "\n",
    "\n",
    "feables = create_feables(match_data, fifa_data, bk_cols_selected, get_overall = True, verbose=True)\n",
    "feables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(n_splits=5, random_state=5, test_size=0.2,\n",
       "            train_size=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = feables.drop('match_api_id', axis = 1)\n",
    "# feables\n",
    "#Exploring the data and creating visualizations\n",
    "labels = inputs.loc[:,'label']\n",
    "features = inputs.drop('label', axis = 1)\n",
    "features.head(5)\n",
    "# feature_details = explore_data(features, inputs, path)\n",
    "# feature_details\n",
    "#Splitting the data into Train, Calibrate, and Test data sets\n",
    "X_train_calibrate, X_test, y_train_calibrate, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42, \n",
    "                                                                        stratify = labels)\n",
    "X_train, X_calibrate, y_train, y_calibrate = train_test_split(X_train_calibrate, y_train_calibrate, test_size = 0.3, random_state = 42, \n",
    "                                                              stratify = y_train_calibrate)\n",
    "\n",
    "# Creating cross validation data splits(like doing 5 separate splits of the same data\n",
    "# but with different test/training set)\n",
    "cv_sets = model_selection.StratifiedShuffleSplit(n_splits = 5, test_size = 0.20, random_state = 5)\n",
    "# type(cv_sets.get_n_splits(X_train, y_train)\n",
    "cv_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished fifa data\n",
      "Generating match features...\n",
      "match stats done\n",
      "       League_21518.0  League_24558.0\n",
      "24207               1               0\n",
      "24208               1               0\n",
      "24209               1               0\n",
      "24210               1               0\n",
      "24211               1               0\n",
      "...               ...             ...\n",
      "25865               0               1\n",
      "25866               0               1\n",
      "25867               0               1\n",
      "25868               0               1\n",
      "25869               0               1\n",
      "\n",
      "[1400 rows x 2 columns]\n",
      "Match features generated in 0.9 minutes\n",
      "Generating match labels...\n",
      "Match labels generated in 0.1 minutes\n",
      "Generating bookkeeper data...\n",
      "Bookkeeper data generated in 0.0 minutes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "d5885082-77bf-70c6-6ab0-0c1f64af3e74"
   },
   "outputs": [],
   "source": [
    "## Initializing all models and parameters\n",
    "#Initializing classifiers\n",
    "RF_clf = RandomForestClassifier(n_estimators = 200, random_state = 1, class_weight = 'balanced')\n",
    "AB_clf = AdaBoostClassifier(n_estimators = 200, random_state = 2)\n",
    "GNB_clf = GaussianNB()\n",
    "KNN_clf =  KNeighborsClassifier()\n",
    "LOG_clf = linear_model.LogisticRegression(multi_class = \"ovr\", solver = \"sag\", class_weight = 'balanced')\n",
    "clfs = [RF_clf, AB_clf, GNB_clf, KNN_clf, LOG_clf]\n",
    "\n",
    "#Specficying scorer and parameters for grid search\n",
    "feature_len = features.shape[1]\n",
    "scorer = make_scorer(accuracy_score)\n",
    "parameters_RF = {'clf__max_features': ['auto', 'log2'], \n",
    "                 'dm_reduce__n_components': np.arange(5, feature_len, np.around(feature_len/5))}\n",
    "parameters_AB = {'clf__learning_rate': np.linspace(0.5, 2, 5), \n",
    "                 'dm_reduce__n_components': np.arange(5, feature_len, np.around(feature_len/5))}\n",
    "parameters_GNB = {'dm_reduce__n_components': np.arange(5, feature_len, np.around(feature_len/5))}\n",
    "parameters_KNN = {'clf__n_neighbors': [3, 5, 10], \n",
    "                  'dm_reduce__n_components': np.arange(5, feature_len, np.around(feature_len/5))}\n",
    "parameters_LOG = {'clf__C': np.logspace(1, 1000, 5), \n",
    "                  'dm_reduce__n_components': np.arange(5, feature_len, np.around(feature_len/5))}\n",
    "\n",
    "parameters = {clfs[0]: parameters_RF,\n",
    "              clfs[1]: parameters_AB,\n",
    "              clfs[2]: parameters_GNB,\n",
    "              clfs[3]: parameters_KNN,\n",
    "              clfs[4]: parameters_LOG}\n",
    "\n",
    "#Initializing dimensionality reductions\n",
    "pca = PCA()\n",
    "dm_reductions = [pca]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of LogisticRegression for training set: 0.5587.\n",
      "Score of LogisticRegression for test set: 0.4308.\n"
     ]
    }
   ],
   "source": [
    "## Training a baseline model and finding the best model composition using grid search\n",
    "#Train a simple GBC classifier as baseline model\n",
    "clf = LOG_clf\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Score of {} for training set: {:.4f}.\".format(clf.__class__.__name__, accuracy_score(y_train, clf.predict(X_train))))\n",
    "print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, accuracy_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "# #Training all classifiers and comparing them\n",
    "# clfs, dm_reductions, train_scores, test_scores = find_best_classifier(clfs, dm_reductions, scorer, X_train, y_train, \n",
    "#                                                                     X_calibrate, y_calibrate, X_test, y_test, cv_sets, \n",
    "#                                                                       parameters, n_jobs)\n",
    "\n",
    "# #Plotting train and test scores\n",
    "# plot_training_results(clfs, dm_reductions, np.array(train_scores), np.array(test_scores), path = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "82202554-bfc1-215d-fb7f-d6b49701cb0c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fca2836e9e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Plotting a confusion matrix of the best model and the bookkeeper predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Defining the best classifier and plotting a confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_dm_reduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm_reductions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best classifier is a {} with {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dm_reduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_scores' is not defined"
     ]
    }
   ],
   "source": [
    "## Plotting a confusion matrix of the best model and the bookkeeper predictions\n",
    "#Defining the best classifier and plotting a confusion matrix\n",
    "best_clf = clfs[np.argmax(test_scores)]\n",
    "best_dm_reduce = dm_reductions[np.argmax(test_scores)]\n",
    "print(\"The best classifier is a {} with {}.\".format(best_clf.base_estimator.__class__.__name__, best_dm_reduce.__class__.__name__)                              )\n",
    "plot_confusion_matrix(y_test, X_test, best_clf, best_dm_reduce, path = path, normalize = True)\n",
    "\n",
    "#Plotting a confusion matrix of bookkeepers\n",
    "plot_bookkeeper_cf_matrix(match_data, bk_cols, path, verbose = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "a1c1c6b7-721f-3f9d-f938-2a82c5efd05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated parameter combination: 1\n",
      "Simulated parameter combination: 2\n",
      "Simulated parameter combination: 3\n",
      "Simulated parameter combination: 4\n",
      "Program run in 16.4 minutes\n",
      "The best return of investment is: -0.45856209150326793\n"
     ]
    }
   ],
   "source": [
    "## Running a grid search to find the best betting strategy based on the prediction model\n",
    "#Finding best betting strategy and profit\n",
    "percentile_grid = np.linspace(0, 1, 2)\n",
    "probability_grid = np.linspace(0, 0.5, 2)\n",
    "best_betting = optimize_betting(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, match_data, fifa_data,\n",
    "                     5, 300, percentile_grid, probability_grid, verbose = True)\n",
    "end = time()    \n",
    "print(\"Program run in {:.1f} minutes\".format((end - start)/60))\n",
    "print(\"The best return of investment is: {}\".format(best_betting.results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e5a6d4e0-0734-e7b5-180a-e1325a889c56"
   },
   "source": [
    "###Conclusion\n",
    "In summary, the results of my project reflect a solid first effort in prediction match outcomes in football using machine learning techniques. By comparing multiple classification algorithms in combination with dimensionality reduction, it was discovered that a logistic regression model in combination with a principal component analysis has the best performance. Combining the model selection and tuning process with cross-validation, the robustness and replicability of results is ensured. I firmly believe that this model selection and tuning process can easily be applied to all sorts of classification problems. Another important aspect of the project is the feature creation process since the variety of features that could be created based on the underlying raw data is extremely high. Since existing approaches to football predictions are considered, I created a variety of features that resulted in final model performance superior to bookkeeper prediction accuracy. Creating these features, choosing what aspects of a football match to take into account for prediction, and ensuring that the set of features as a whole fully reflects the bandwidth of facets of a football match was certainly the most difficult part of this project. It remains that football matches are affected by countless factors as well as a high degree of randomness, which makes it impossible to achieve perfect prediction accuracy in my opinion. However, I believe that given more data sources, it is certainly possible to further increase the performance of the model. \n",
    "\n",
    "\n",
    "###Improvement\n",
    "\n",
    "There are several ways to improve the performance of the current implementation, related to, both, feature creation and model training as well as the betting strategy algorithm. First, more data sources could be included in the analysis to further strengthen model performance, e.g. one could include detailed match data such as ball possession as well as shots-on-goal statistics. Second, the model selection process could be further expanded to include more model types as well as feature selection algorithms, however, I am confident that no significant improvements in model performance are achievable in such a manor. Third, the algorithm to translate probability predictions of the final model into a betting strategy could be significantly improved. For instance, one could experiment with varying the amount per bet based on a measure confidence that the model outperforms the bookkeeper.\n",
    "In my honest opinion, I believe it could be possible to predict as much as 65 to 70 percent of matches accurately. Unfortunately, my code can only be run on a sample of all matches on Kaggle due to run time restrictions. The results mentioned in this section are b\n",
    "\n",
    "This is my second machine learning and my first python project. Therefore, please feel free to suggest improvements to the methodology as well as the code. I hope my project can be a basis for more successful attempts to match outcome prediction and will ultimately result in a prediction-based betting strategy that is robust in generating a positive return of investment. Looking forward to hearing your opinion! on running the program on the full data set."
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
